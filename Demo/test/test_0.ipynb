{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    df_origin = pd.read_csv(file)\n",
    "\n",
    "    df = df_origin.replace(['Benign/Likely_benign', 'Pathogenic/Likely_pathogenic'], ['Likely_benign', 'Likely_pathogenic']) \n",
    "\n",
    "    df.drop(df[(df['CLNSIG'] != 'Benign') & (df['CLNSIG'] != 'Pathogenic') & (df['CLNSIG'] != 'Likely_benign') & (df['CLNSIG'] != 'Likely_pathogenic')].index, inplace=True)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(['index', 'Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_csv('../../Data/train/data_z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_consequence(df):\n",
    "    con_split = df['Consequence'].apply(lambda x: x if pd.isna(x) else x.split('&'))\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    con_df = pd.DataFrame(mlb.fit_transform(con_split), columns=mlb.classes_)\n",
    "\n",
    "    return con_df\n",
    "\n",
    "con_df = multi_hot_consequence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "integenic = ['intergenic_variant', 'upstream_gene_variant', 'downstream_gene_variant']\n",
    "# 1 if(set(integenic) & set(con_df.columns)) else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_div(con_df):\n",
    "    # 基因间区：（这个对整体致病性影响较小）\n",
    "    integenic = ['intergenic_variant', 'upstream_gene_variant', 'downstream_gene_variant']\n",
    "    con_df['integenic'] = con_df[list(set(integenic) & set(con_df.columns))].sum(axis=1).apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # UTR区域：\n",
    "    utr = ['5_prime_UTR_variant', '5_prime_UTR_variant']\n",
    "    con_df['utr'] = con_df[list(set(utr) & set(con_df.columns))].sum(axis=1).apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # 内含子区域：\n",
    "    intron = ['intron_variant']\n",
    "\n",
    "    # 外显子区域：\n",
    "    exon = ['synonymous_variant', 'missense_variant', 'inframe_insertion', 'inframe_deletion', 'stop_gained', 'frameshift_variant', 'coding_sequence_variant', 'stop_lost', 'stop_retained_variant', 'start_lost', 'stop_retained_variant', 'incomplete_terminal_codon_variant']\n",
    "    con_df['exon'] = con_df[list(set(exon) & set(con_df.columns))].sum(axis=1).apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # 在UTR,内含子和外显子的交界处，存在splice区域\n",
    "    splice = ['splice_acceptor_variant', 'splice_donor_variant', 'splice_region_variant']\n",
    "    con_df['splice'] = con_df[list(set(splice) & set(con_df.columns))].sum(axis=1).apply(lambda x: 1 if x else 0)\n",
    "\n",
    "region_div(con_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df, con_df):\n",
    "    df_copy = df.merge(con_df, left_on=df.index, right_on=con_df.index)\n",
    "    df_copy.drop('key_0', axis=1, inplace=True)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "df_copy = merge_df(df, con_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EXON(df):\n",
    "    df_EXON = df[df['EXON'].notna()]\n",
    "    return df_EXON\n",
    "\n",
    "df_EXON = get_EXON(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_EXON['FATHMM_pred'].value_counts()\n",
    "a = 'T&T&T&T&.&T&T&T&D'\n",
    "a.split('&').count('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exon_format(df_EXON):\n",
    "    # df_EXON['INTRON'] = df_EXON['INTRON'].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "\n",
    "    def del_brackets(x):\n",
    "        res = re.sub(u'\\\\(.*?\\\\)', '', x)\n",
    "        return res\n",
    "\n",
    "    df_EXON['SIFT'] = df_EXON['SIFT'].apply(lambda x: x if pd.isna(x) else del_brackets(x))\n",
    "\n",
    "    df_EXON['SIFT_pred'] = df_EXON['SIFT_pred'].apply(lambda x: x if pd.isna(x) else max(string.ascii_uppercase, key=x.count))\n",
    "\n",
    "    df_EXON['PolyPhen'] = df_EXON['PolyPhen'].apply(lambda x: x if pd.isna(x) else del_brackets(x))\n",
    "\n",
    "    # def percent(x, D, T):\n",
    "        \n",
    "    #     sum = 1 if x.count(D) + x.count(T) == 0 else x.count(D) + x.count(T)\n",
    "    #     return count1 / sum\n",
    "        \n",
    "    df_EXON['FATHMM_pred'] = df_EXON['FATHMM_pred'].apply(lambda x: x if pd.isna(x) else percent(x, 'D', 'T'))\n",
    "\n",
    "    df_EXON['MutationTaster_pred'] = df_EXON['MutationTaster_pred'].apply(lambda x: x if pd.isna(x) else max(string.ascii_uppercase, key=x.count))\n",
    "                                                                                \n",
    "    df_EXON['PROVEAN_pred'] = df['PROVEAN_pred'].apply(lambda x: x if pd.isna(x) else percent(x, 'D', 'N'))\n",
    "\n",
    "    df_EXON['Polyphen2_HDIV_pred'] = df_EXON['Polyphen2_HDIV_pred'].apply(lambda x: x if pd.isna(x) else max(string.ascii_uppercase, key=x.count))\n",
    "\n",
    "    df_EXON['Polyphen2_HVAR_pred'] = df_EXON['Polyphen2_HVAR_pred'].apply(lambda x: x if pd.isna(x) else max(string.ascii_uppercase, key=x.count))\n",
    "\n",
    "    def vest3_avr(x):\n",
    "        ss = x.split('&')\n",
    "        sum = 0\n",
    "        index = 0\n",
    "        for i in ss:\n",
    "            sum += float(i)\n",
    "            index += 1\n",
    "        return sum / index\n",
    "\n",
    "    df_EXON['VEST3_score'] = df_EXON['VEST3_score'].apply(lambda x: x if pd.isna(x) else vest3_avr(x))\n",
    "\n",
    "    # df_INTRON['']\n",
    "    # ada_score\n",
    "    # df_INTRON['ada_score'] = df_INTRON['ada_score'].fillna(df_INTRON.groupby('Consequence')['ada_score'].transform('mean'))\n",
    "\n",
    "    # rf_score\n",
    "    # df_INTRON['rf_score'] = df_INTRON['rf_score'].fillna(df_INTRON.groupby('Consequence')['rf_score'].transform('mean'))\n",
    "\n",
    "    df_EXON['gnomadWES_AF_POPMAX'] = df_EXON['gnomadWES_AF_POPMAX'].apply(lambda x: 0 if (pd.isna(x)) or (x == '.') else float(x))\n",
    "    df_EXON['AF'] = df_EXON.apply(lambda x: np.mean([x['MAX_AF'], float(x['gnomadWES_AF_POPMAX'])]), axis=1)\n",
    "\n",
    "# exon_format(df_EXON)\n",
    "# print(type(format(df_EXON)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7067752808525d7ffbb24c869c880589a40eef7552d9209287e063480e198c9f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
